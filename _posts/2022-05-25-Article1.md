---
layout: single
title:  \[논문리뷰]Collaborative Filtering for Implicit Feedback Datasets
categories: 추천시스템
tag: [article, recommendation]
use_math: true
toc: true
author_profile: true
sidebar:
  nav: docs
---

암시적 데이터(implicit feedback data)를 협업 필터링 추천시스템에서 이용하는 방법에 대해서 다루는 논문입니다. 

### 1. **주요 아이디어**

추천시스템들은 유저의 상품에 대한 평가와 같은 명시적 피드백에 의존하는 경우가 많습니다. 이러한 명시적 평가 데이터는 그 자체가 유저의 선호로 생각되기 때문에 중요합니다. 하지만 실제 시스템에서 유저들은 평가를 잘 하지 않는 경향이 있습니다. 때문에 이 논문에서는 유저의 암시적 피드백을 이용하여 협업 필터링 추천시스템을 사용하는 방법을 설명하고 있습니다. 암시적 피드백의 종류에는 구매이력, 브라우징 이력, 검색 패턴 등을 예로 들 수 있습니다. 저는 논문과 테스트에서 TV 프로그램을 사용하므로, 암시적 피드백은 유저가 한 TV 프로그램 을 얼마나 봤는지로 설정하여 설명드리겠습니다.

### 2. **암시적 데이터의 특징** 

논문에서는 암시적 데이터의 특징을 정의내리고 있습니다.

1) 부정적인 피드백의 부재

유저가 한 TV 프로그램을 많이 봤다면 그 프로그램을 좋아한다고 추론이 가능하지만, 보지 않았다고 해서 그 프로그램을 싫어한다고 추론하는 것은 불가능합니다. 유저는 프로그램을 자체를 몰랐거나, 볼 상황이 안되었을 수도 있습니다.

2) 암시적 피드백의 노이즈

 암시적 피드백에는 항상 노이즈가 존재합니다. 한 유저가 한 TV 프로그램을 계속 틀고 있었더라도 유저는 그 프로그램을 보지 않고 자거나 다른 일을 하고 있을 수도 있습니다. 이 때 데이터는 유저의 선호와는 관계가 없는 노이즈로 생각될 수 있습니다.

3) 암시적 피드백의 값은 신뢰도를 나타낸다.

명시적 피드백의 값은 선호와 직결되는 개념이지만 암시적 피드백은 신뢰도와 관련되어 있습니다. 신뢰도란 유저가 다음에도 같은 행동을 할 것으로 믿을 수 있는 정도라고 설명할 수 있습니다. 예를 들어, 시청 빈도를 피드백으로 사용했을 때 한 유저가 영화는 한번 시청했고, 시리즈물은 여러 번 시청했다고 가정해봅시다. 이 경우에 유저는 영화를 한번 봤지만 시리즈물보다 영화를 더 좋아할 수도 있습니다. 시리즈물의 특성 때문에 해석에 오해가 생기는 것입니다. 이 때문에 암시적 피드백을 선호보다는 신뢰도로 생각하는 것이 논리적입니다.

4) 암시적 피드백을 사용하는 추천시스템은 적절한 평가기준이 필요하다.

명시적 피드백은 그 자체가 선호에 대한 점수이기 때문에 MSE 같은 평가기준을 사용할 수 있지만, 암시적 피드백은 동시간 대 시청경쟁, 시청여건, 반복되는 시청 등의 경우들을 고려해야 합니다. 이 때문에 새로운 평가 기준을 마련해야 합니다.

### 2. **서론**

논문에서 사용하는 파라미터에 대해서 정의 내리고 있습니다.

모델을 설명하기 위해 유저는 u,v, 프로그램은 i,j 로 표현하고, 유저와 아이템을 $r_{ui}$ 값을 통해서 연결합니다.  $r_{ui}$는 관찰값으로써 유저 u가 얼마나 프로그램 i를 봤는지 나타냅니다. $r_{ui} = 0.7$ 은 유저 u가 프로그램 i의 70%를 봤다는 것을 나타내고, 마찬가지로 프로그램을 두 번 본 유저는 $r_{ui} = 2$ 로 나타낼 수 있습니다. 또한 암시적 피드백은 해당 행동이 없으면 $r_{ui}$는 0이 됩니다.이렇게 0으로 표현할 수 있다는 것 자체가 암시적 피드백의 장점으로 설명할 수 있다. 명시적 피드백 시스템에서는 유저-프로그램 쌍의 평가 점수를 모르는 경우가 많고, 이러한 값은  결측치로 생각되어 많은 값들이 무시됩니다. 암시적 피드백은 무시되는 값 없이 계산이 가능하기 때문에 명시적 피드백에 비해 유리하다고 생각할 수 있습니다.

### 3. 기존 **모델과 제안 모델**

1) 최근접 이웃 협업 필터링 모델

이 모델은 사용자 접근과 아이템 접근 방식으로 나뉩니다. 사용자 접근 방식은 각 사용자가 평가한 프로그램 점수를 통해서 사용자들 사이의 유사성을 측정하고 유사성이 높은 다른 사용자를 통해 해당 사용자의 평가 점수를 예측하는 방식입니다. 아이템 접근 방식은 각 프로그램의 유저 평가 점수를 통해 프로그램들 사이의 유사성을 측정하고 유사성이 높은 다른 프로그램을 통해 해당 아이템의 평가 점수를 예측하는 방식입니다.  다음과 같은 식으로 예측 점수를 계산한다.

$\hat{r}_{ui} = \frac{\sum{j\in{S^k(i:u)}}S_{ij}r_{uj}}{\sum_{j\in{S^k(i:u)}}S_{ij}}$

$\hat{r}_{ui}$는 예측된 점수를 나타냅니다. $S^k(i;u)$는 유저 u가 평가한 프로그램 i와 유사성이 높은 프로그램 k 의 집합입니다.  $S_{ij}$는 i와 j의 유사성을 나타내고, 이는 보통 피어슨 상관계수를 사용합니다.

즉, 식을 해석해보면 먼저 분자는 $S^k(i;u)$에 속한 모든 프로그램 j에 대해서 프로그램 i와의 유사성을 계산하고 이를 유저 u가 프로그램 j에 대해 평가한 점수와 곱해줍니다. 그리고 이를 모두 합해줍니다.  분모는 모든 j에 대해서 i와 j의 유사성을 구해주고 합해줍니다. 결과적으로 $\hat{r}_{ui}$는 유사성이 높은 프로그램들의 평가들이  가중되어 있는 것을 평균낸 것으로 생각할 수 있습니다.

2) 잠재 기반 협업 필터링

이 모델은 유저 - 프로그램 평가 점수 행렬을 분해하여 평가 점수를 예측하는 방식입니다. 유저 - 프로그램 행렬은 확률적 경사 하강법을 통해서 유저 - 잠재요인 행렬 $x_u$와 프로그램 - 잠재요인 행렬 $y_i$로 분해됩니다. 이 두 행렬을 내적곱함으로써 값이 모두 채워진 행렬을 얻을 수 있는데 이 값들이 예측 점수로 사용됩니다. 비용함수는 다음과 같습니다.

 $min_{x, y} \sum_{r_{u,i} is known}{(r_{ui} - x^{T}_{u}y_{i})}^2 + \lambda(\rVert x_{u} \rVert^2 + \rVert y_{i} \rVert^2)$

경사하강법에서 많이 사용되는 비용함수입니다. 오차에 L2규제가 더해진 형식입니다.  $(r_{ui} - x^{T}y{i})^2$ 부분은 예측오차이고,  $\lambda(\rVert x_{u} \rVert^2 + \rVert y_{i} \rVert^2)$ 는 L2 규제에 따른 식입니다.  L2 규제는 각 $x_{u}$와 $y_{i}$가 0이 되지 않게 해주고,  가중치가 골고루 분배되게 하는 이점이 있다고 합니다. 

이 식을 x와 y로 편미분한 후, 함수값을 0으로 설정하고 x와 y에 대한 식으로 만들어주면, 다음과 같이 계산된다.

$\hat{x}_{u} = x_{u} + \eta(e_{ui} * y_{i} - \lambda * x_{u})$

$\hat{y}_{i} = y_{i} + \eta(e_{ui} * x_{u} - \lambda * y_{i})$

 $\eta$ 는 학습률, $e_{ui}$는 예측 오차를 뜻합니다. 이 값을 통해 최적값을 향해 계속 업데이트됩니다. 예측오차와 규제를 통해서 오버피팅은 피하고 최적화된 값을 찾게 됩니다. 이 논문에서는 암시적 피드백을 사용하기 위해 이 모델에 기반하되, 파라미터를 바꿔줍니다.

3) 협업 필터링 : 암시적 피드백 사용 - 제안모델

ㄱ. 모델 구조

암시적 피드백을 사용하기 위해 먼저 파라미터들을 바꿔줄 필요가 있습니다.

먼저 $r_{ui}$를 이항 변수인 $p_{ui}$로 바꿔줍니다.

$p_{ui} = \begin{cases}1 & r_{ui} > 0 \\0 & r_{ui}=0 \end{cases}$

 $p_{ui}$는 선호하는 지, 선호하지 않는 지를 표현합니다. 유저가 프로그램을 조금만 봐도($r_{ui}$ > 0) 선호한다고 표현하는 것입니다. 하지만 위에서 설명했던 것처럼 암시적 피드백에서는 $r_{ui}$ 를 신뢰도와 함께 엮어서 생각해주어야 합니다. 이러한 신뢰도를 표현하기 위해서 $c_{ui}$ 라는 신뢰도 변수를 하나 더 만들어 줍니다. 

$c_ {ui} = 1 + \alpha r_{ui}$

알파 값과 r_{ui}를 곱한 값과 여기에 1을 더한 값을 사용해서 선호에 대한 신뢰도를 표현합니다. 알파 값은 실험 후에 가장 결과가 좋았던 40으로 채택한다고 합니다.

이 모델에서는 확률적 경사하강법 대신 Alternating-Least-Squares(교차최소제곱법) 를 사용합니다. 비용함수는 다음과 같습니다.

$min_{x, y} \sum_{u,i}{c_{ui}(p_{ui} - x^{T}_{u}y_{i})}^2 + \lambda(\sum_{\rVert x_{u} \rVert^2} + \sum_{\rVert y_{i} \rVert^2})$ 

전체적인 형태는 확률적 경사하강법과 비슷합니다. $p_{ui}$는 벡터 $x_{u}$ 와 벡터 $y_{i}$ 로 분해하고, 두 벡터의 곱을 통해 예측값을 구합니다. 하지만 $c_{ui}$ 를 곱해주는 부분에서 신뢰도 값이 계산됩니다.

ALS 는 업데이트 시에 다른 파라미터를 고정한 후에 업데이트한다는 점에서 경사하강법과는 차이가 있습니다.
경사하강법의 경우에, 모든 파라미터(가중치)가 한번에 계산되기 때문에 계산에 부하가 걸립니다. ALS는 한번에 계산하지 않고, 하나의 파라미터를 업데이트 할때 다른 파라미터는 고정하는 방식으로 번갈아가며 업데이트합니다. 이러한 처리는 예측오차가 희소행렬이 아닌 밀집행렬로 나타나는 암시적 피드백의 계산상황에서 확률적 경사하강법에 비해 빠른 계산이 가능하기 때문에 장점으로 나타납니다. 

마찬가지로 x와 y로 편미분한 후, 함수값을 0으로 설정하고 x와 y에 대한 식으로 만들어주면, 다음과 같이 식을 구할 수 있습니다.

$\hat{x}_{u} = (Y^TC^uY + λI)^{−1}Y^TC^up(u)$

$\hat{y}_{i} = (X^TC^iX + λI)^{−1}X^TC^ip(i)$

$C^{u}$ 는 미분과정에서 $c_{ui}$ 로 부터 나온 대각행렬이고, p(u) 는 $p_{ui}$ 유저 u로 표현된 p 벡터이다. y에 관한 식도 마찬가지로 표현됩니다.

결과적으로, 선호도 예측 값인 $\hat{p}_{ui}$은  $\hat{x}^T \hat{y}_{i}$ 로 구해집니다.

ㄴ. 추천에 대한 설명 용이

이 모델에서 중요한 점은 추천에 대한 설명이 2) 모델 보다 더 쉬워진다는 것입니다.  $\hat{p}_{ui}$는 내적이므로 풀어쓰면 다음과 같이도 표현할 수 있습니다.

 $\hat{p}_{ui}$ =  $\hat{y}^T_{i}\hat{x}_u = \hat{y}^T_{i}(Y^TC^uY + λI)^{−1}Y^TC^up(u)$

이 식에서 (Y^TC^uY + λI)^{−1}를 가중치 W^{u}로 가정하고, 유저 u의 입장에서 바라봤을 때 다음과 같은 식을 얻게 됩니다.

 $\hat{p}_{ui} = \hat{y}_{i}^TW^{u}y_{j}c_{ui}$  

유저 u 입장에서 $\hat{y}{i}^TW^{u}y_{j}$ 는 프로그램 i에 대한 벡터인 $y_{i}$ 와 가중치가 곱해진 다른 프로그램 j에 대한 벡터인 $y_{j}$ 가 곱해진 모습은 마치 모델 1)에서의 유사성 $s_{ij}$와 비슷하게 생각할 수 있습니다. 이를 식으로 나타내보면 다음과 같이 나타낼 수 있습니다.

$\hat{p}_{ui} = \sum_{j:r_{ui}>0}{s^{u}_{ij}c_{uj}}$

$s^{u}_{ij}$는 프로그램간의 유사도로 생각할 수 있고, $c_{uj}$은 유저 u의 프로그램 j 에 대한 신뢰도로 생각할 수 있습니다.

### 5. 테스트

논뭄에서 진행한 모델 테스트에 대한 내용입니다.

셋탑박스의 tv프로그램 시청기록을 통해 실험을 진행했는데 4주간의 시청기록을 학습데이터로 사용하고, 뒤의 한 주를 테스트데이터로 사용하였다고 합니다.

암시적 피드백의 특성을 고려하여, 데이터셋을 구성했다고합니다.
1. 이전에 본 것은 또 볼 확률이 높기 때문에 테스트 데이터에서 학습데이터에 있는 프로그램은 제거했다고 합니다.

2. 한 프로그램이 끝나고 연속으로 방영되는 프로그램도 가중치를 주어 영향을 낮게 주도록 설정했다고 합니다. 

1) 평가함수

논문에서는 1의 4)에서 설명한대로 새로운 암시적 피드백을 위한 새로운 평가기준을 생성하여 이 지표를 사용하여 모델을 평가합니다. 

$\bar{rank} = \frac{\sum_{}r^t_{ui}rank_{ui}}{\sum_{ui}r^{t}_{ui}}$

$r_{ui}^{t}$ 는 테스트 데이터셋의 관찰값이고, $rank_{ui}$는 예측점수에 따라 프로그램을 나열한 리스트를 percentile로 바꿔준 것입니다. 때문에 낮을 수록 순위가 높고, $\bar{rank}$ 또한 식에 의해 낮을 수록 좋다고 합니다. 이러한 평가기준은 재현율을 참고한 것입니다. 분모는 TP + FN으로 생각할 수 있고, 분자는 관찰값과 랭크를 곱하여 TP를 구했다고 볼 수 있습니다. 암시적 데이터의 경우, 1의 1)에서 설명한 것처럼 FP를 설명하기 어렵기 때문에 재현율 기반의 평가함수를 사용했다고 합니다. 

### 6. 결과

![cf.PNG](/assets/images/article/cf.png)

인기순위로 추천한 Popularity와 프로그램- 프로그램 유사성 기반의 모델 1)로 성능을 비교했다고 합니다. 제안모델은 요인이 많아질 수록 낮은 랭크 값을 보이다가 일정 수준에서 정체되고 제안모델은 표에서 보이듯이 타 모델보다 낮은 랭크값을 보이는 것을 확인할 수 있습니다.

다음에는 코드로 구현해볼 예정입니다.

오늘 포스팅은 여기까지 입니다.
