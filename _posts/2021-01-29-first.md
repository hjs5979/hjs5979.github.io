---
layout: single
title:  "신용등급 예측 대회"
---

# 데이콘 신용카드 사용자 연체 예측 AI 경진대회

### 변수설명


- gender: 성별


- car: 차량 소유 여부


- reality: 부동산 소유 여부


- child_num: 자녀 수


- income_total: 연간 소득


- income_type: 소득 분류, ['Commercial associate', 'Working', 'State servant', 'Pensioner', 'Student']



- edu_type: 교육 수준, ['Higher education' ,'Secondary / secondary special', 'Incomplete higher', 'Lower secondary', 'Academic degree']


- family_type: 결혼 여부, ['Married', 'Civil marriage', 'Separated', 'Single / not married', 'Widow']


- house_type: 생활 방식, ['Municipal apartment', 'House / apartment', 'With parents','Co-op apartment', 'Rented apartment', 'Office apartment']


- DAYS_BIRTH: 출생일, 데이터 수집 당시 (0)부터 역으로 셈, 즉, -1은 데이터 수집일 하루 전에 태어났음을 의미


- DAYS_EMPLOYED: 업무 시작일, 데이터 수집 당시 (0)부터 역으로 셈, 즉, -1은 데이터 수집일 하루 전부터 일을 시작함을 의미, 양수 값은 고용되지 않은 상태를 의미함


- FLAG_MOBIL: 핸드폰 소유 여부


- work_phone: 업무용 전화 소유 여부


- phone: 전화 소유 여부


- email: 이메일 소유 여부


- occyp_type: 직업 유형		


- family_size: 가족 규모


- begin_month: 신용카드 발급 월, 데이터 수집 당시 (0)부터 역으로 셈, 즉, -1은 데이터 수집일 한 달 전에 신용카드를 발급함을 의미


- credit: 사용자의 신용카드 대금 연체를 기준으로 한 신용도 => 낮을 수록 높은 신용의 신용카드 사용자를 의미함


```python
import pandas as pd
```


```python
# 20220418 데이터 업데이트시 수정 예정
train=pd.read_csv('./train.csv')
test=pd.read_csv('./test.csv')
```

# EDA

## 기본 EDA


```python
train.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 26457 entries, 0 to 26456
    Data columns (total 20 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   index          26457 non-null  int64  
     1   gender         26457 non-null  object 
     2   car            26457 non-null  object 
     3   reality        26457 non-null  object 
     4   child_num      26457 non-null  int64  
     5   income_total   26457 non-null  float64
     6   income_type    26457 non-null  object 
     7   edu_type       26457 non-null  object 
     8   family_type    26457 non-null  object 
     9   house_type     26457 non-null  object 
     10  DAYS_BIRTH     26457 non-null  int64  
     11  DAYS_EMPLOYED  26457 non-null  int64  
     12  FLAG_MOBIL     26457 non-null  int64  
     13  work_phone     26457 non-null  int64  
     14  phone          26457 non-null  int64  
     15  email          26457 non-null  int64  
     16  occyp_type     18286 non-null  object 
     17  family_size    26457 non-null  int64  
     18  begin_month    26457 non-null  int64  
     19  credit         26457 non-null  int64  
    dtypes: float64(1), int64(11), object(8)
    memory usage: 4.0+ MB
    


```python
train.describe(include='all')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>gender</th>
      <th>car</th>
      <th>reality</th>
      <th>child_num</th>
      <th>income_total</th>
      <th>income_type</th>
      <th>edu_type</th>
      <th>family_type</th>
      <th>house_type</th>
      <th>DAYS_BIRTH</th>
      <th>DAYS_EMPLOYED</th>
      <th>FLAG_MOBIL</th>
      <th>work_phone</th>
      <th>phone</th>
      <th>email</th>
      <th>occyp_type</th>
      <th>family_size</th>
      <th>begin_month</th>
      <th>credit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>26457.000000</td>
      <td>26457</td>
      <td>26457</td>
      <td>26457</td>
      <td>26457.000000</td>
      <td>2.645700e+04</td>
      <td>26457</td>
      <td>26457</td>
      <td>26457</td>
      <td>26457</td>
      <td>26457.000000</td>
      <td>26457.000000</td>
      <td>26457.0</td>
      <td>26457.000000</td>
      <td>26457.000000</td>
      <td>26457.000000</td>
      <td>18286</td>
      <td>26457.000000</td>
      <td>26457.000000</td>
      <td>26457.000000</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>NaN</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5</td>
      <td>5</td>
      <td>5</td>
      <td>6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>18</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>top</th>
      <td>NaN</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Working</td>
      <td>Secondary / secondary special</td>
      <td>Married</td>
      <td>House / apartment</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Laborers</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>NaN</td>
      <td>17697</td>
      <td>16410</td>
      <td>17830</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>13645</td>
      <td>17995</td>
      <td>18196</td>
      <td>23653</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4512</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>13228.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.428658</td>
      <td>1.873065e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-15958.053899</td>
      <td>59068.750728</td>
      <td>1.0</td>
      <td>0.224742</td>
      <td>0.294251</td>
      <td>0.091280</td>
      <td>NaN</td>
      <td>2.196848</td>
      <td>-26.123294</td>
      <td>1.519560</td>
    </tr>
    <tr>
      <th>std</th>
      <td>7637.622372</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.747326</td>
      <td>1.018784e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4201.589022</td>
      <td>137475.427503</td>
      <td>0.0</td>
      <td>0.417420</td>
      <td>0.455714</td>
      <td>0.288013</td>
      <td>NaN</td>
      <td>0.916717</td>
      <td>16.559550</td>
      <td>0.702283</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>2.700000e+04</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-25152.000000</td>
      <td>-15713.000000</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>1.000000</td>
      <td>-60.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>6614.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>1.215000e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-19431.000000</td>
      <td>-3153.000000</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>2.000000</td>
      <td>-39.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>13228.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.000000</td>
      <td>1.575000e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-15547.000000</td>
      <td>-1539.000000</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>2.000000</td>
      <td>-24.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>19842.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.000000</td>
      <td>2.250000e+05</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-12446.000000</td>
      <td>-407.000000</td>
      <td>1.0</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>3.000000</td>
      <td>-12.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>26456.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>19.000000</td>
      <td>1.575000e+06</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-7705.000000</td>
      <td>365243.000000</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>NaN</td>
      <td>20.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
import matplotlib.pyplot as plt 
train.plot(kind='box',subplots=True,layout = (7,4),figsize=(20,30))
plt.tight_layout()
plt.show()
```


    
![png](output_8_0.png)
    



```python
import seaborn as sns
import matplotlib.pyplot as plt

# sns.pairplot(train)
```


```python
train.duplicated(subset=['income_total', 'DAYS_BIRTH'], keep=False).value_counts()
```




    True     23367
    False     3090
    dtype: int64



### 기본 EDA 결과
1. child_num, days_employed, family_size, income_total에서 이상치 발견
-> income_total은 변수 특성에 따라 이상치 처리를 할 필요성이 적고 나머지는 이상치 처리가 필요해 보임.


2. child_num과 family_size는 상관관계가 있음.


3. 23367개의 행이 중복관계에 있음.

## 변수분석


```python
# 인덱스 미리 제거
train.drop(['index'], axis=1, inplace=True)
```


```python
# 숫자형 변수와 범주형 변수 미리 분리
cate_feat = []
num_feat = []
for col in train.columns:
    target = train[col]
    if target.nunique() <=20:
        cate_feat.append(col)
    else:
        num_feat.append(col)
print('범주형 :', cate_feat)
print('연속형: ', num_feat)
```

    범주형 : ['gender', 'car', 'reality', 'child_num', 'income_type', 'edu_type', 'family_type', 'house_type', 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'occyp_type', 'family_size', 'credit']
    연속형:  ['income_total', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month']
    

### 범주형 변수

#### gender


```python
var = cate_feat[0]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    F    17697
    M     8760
    Name: gender, dtype: int64
    


    
![png](output_17_1.png)
    


이상치 처리하고, 범주형으로 처리.

#### car


```python
var = cate_feat[1]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    N    16410
    Y    10047
    Name: car, dtype: int64
    


    
![png](output_20_1.png)
    


변별력이 있는 변수인지 의문

#### reality


```python
var = cate_feat[2]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    Y    17830
    N     8627
    Name: reality, dtype: int64
    


    
![png](output_23_1.png)
    


#### child_num


```python
var = cate_feat[3]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    0     18340
    1      5386
    2      2362
    3       306
    4        47
    5        10
    14        3
    7         2
    19        1
    Name: child_num, dtype: int64
    


    
![png](output_25_1.png)
    


#### income_type


```python
var = cate_feat[4]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    Working                 13645
    Commercial associate     6202
    Pensioner                4449
    State servant            2154
    Student                     7
    Name: income_type, dtype: int64
    


    
![png](output_27_1.png)
    


#### edu_type


```python
var = cate_feat[5]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    Secondary / secondary special    17995
    Higher education                  7162
    Incomplete higher                 1020
    Lower secondary                    257
    Academic degree                     23
    Name: edu_type, dtype: int64
    


    
![png](output_29_1.png)
    


#### family_type


```python
var = cate_feat[6]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    Married                 18196
    Single / not married     3496
    Civil marriage           2123
    Separated                1539
    Widow                    1103
    Name: family_type, dtype: int64
    


    
![png](output_31_1.png)
    


#### house_type


```python
var = cate_feat[7]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    House / apartment      23653
    With parents            1257
    Municipal apartment      818
    Rented apartment         429
    Office apartment         190
    Co-op apartment          110
    Name: house_type, dtype: int64
    


    
![png](output_33_1.png)
    


#### FLAG_MOBIL


```python
var = cate_feat[8]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    1    26457
    Name: FLAG_MOBIL, dtype: int64
    


    
![png](output_35_1.png)
    


0값이 없음 -> 의미없는 변수

#### work_phone


```python
var = cate_feat[9]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    0    20511
    1     5946
    Name: work_phone, dtype: int64
    


    
![png](output_38_1.png)
    


#### phone


```python
var = cate_feat[10]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    0    18672
    1     7785
    Name: phone, dtype: int64
    


    
![png](output_40_1.png)
    


#### email


```python
var = cate_feat[11]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(12,6))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    0    24042
    1     2415
    Name: email, dtype: int64
    


    
![png](output_42_1.png)
    


#### occyp_type


```python
var = cate_feat[12]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(15,8))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    Laborers                 4512
    Core staff               2646
    Sales staff              2539
    Managers                 2167
    Drivers                  1575
    High skill tech staff    1040
    Accountants               902
    Medicine staff            864
    Cooking staff             457
    Security staff            424
    Cleaning staff            403
    Private service staff     243
    Low-skill Laborers        127
    Waiters/barmen staff      124
    Secretaries                97
    Realty agents              63
    HR staff                   62
    IT staff                   41
    Name: occyp_type, dtype: int64
    


    
![png](output_44_1.png)
    


#### family_size


```python
var = cate_feat[13]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(15,8))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    2     14106
    1      5109
    3      4632
    4      2260
    5       291
    6        44
    7         9
    15        3
    9         2
    20        1
    Name: family_size, dtype: int64
    


    
![png](output_46_1.png)
    


#### credit


```python
var = train.columns[14]

print(train[var].value_counts())

f, ax = plt.subplots(1,2,figsize=(15,8))

sns.countplot(x=var,hue='credit',data=train, ax=ax[0])
plt.sca(ax[0])
plt.xticks(rotation=90)

sns.pointplot(x=var,y='credit',data=train, ax=ax[1],join=False)
plt.sca(ax[1])
plt.xticks(rotation=90)

plt.show()
```

    2    16968
    1     6267
    0     3222
    Name: credit, dtype: int64
    


    
![png](output_48_1.png)
    


### 숫자형 변수

#### income_total


```python
var = num_feat[0]

f, axes = plt.subplots(1, figsize=(8, 6))

sns.histplot(x=train[var],bins=10,hue=train['credit'])
```




    <AxesSubplot:xlabel='income_total', ylabel='Count'>




    
![png](output_51_1.png)
    


#### DATS_BIRTH


```python
var = num_feat[1]

f, axes = plt.subplots(1, figsize=(8, 6))

sns.histplot(x=train[var],bins=10,hue=train['credit'])
plt.show()
```


    
![png](output_53_0.png)
    


#### DAYS_EMPLOYED


```python
var = num_feat[2]

f, axes = plt.subplots(1, figsize=(8, 6))

sns.histplot(x=train[var],bins=10,hue=train['credit'])
plt.show()
```


    
![png](output_55_0.png)
    


#### begin_month


```python
var = num_feat[3]

f, axes = plt.subplots(1, figsize=(8, 6))

sns.histplot(x=train[var], bins=15 ,hue=train['credit'])
plt.show()
```


    
![png](output_57_0.png)
    



```python
import numpy as np
import pandas as pd
import torch

from catboost import CatBoostClassifier, Pool
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from pytorch_tabnet.multitask import TabNetMultiTaskClassifier
from sklearn.metrics import log_loss
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
```


```python
#데이터 전처리

def category_income(data: pd.DataFrame) -> pd.DataFrame: #income_total 을 크기에 따라 분류하는 함수 ex) 400000 -> 2로 바뀜
    data["income_total"] = data["income_total"] / 10000
    conditions = [
        (data["income_total"].le(18)), #le은 보다 작은, gt는 보다 큰
        (data["income_total"].gt(18) & data["income_total"].le(33)),
        (data["income_total"].gt(33) & data["income_total"].le(49)),
        (data["income_total"].gt(49) & data["income_total"].le(64)),
        (data["income_total"].gt(64) & data["income_total"].le(80)),
        (data["income_total"].gt(80) & data["income_total"].le(95)),
        (data["income_total"].gt(95) & data["income_total"].le(111)),
        (data["income_total"].gt(111) & data["income_total"].le(126)),
        (data["income_total"].gt(126) & data["income_total"].le(142)),
        (data["income_total"].gt(142)),
    ]
    choices = [i for i in range(10)]

    data["income_total"] = np.select(conditions, choices) #조건에 따라 choice에서 선택
    return data

#lgb, xgb 데이터 전처리
def load_dataset() -> Tuple[pd.DataFrame, pd.DataFrame]: #데이터셋 불러오기
    path = "/content/drive/MyDrive/data/"
    train = pd.read_csv(path + "train.csv")
    train = train.drop(["index"], axis=1) #index열 버림 
    train.fillna("NAN", inplace=True) #결측치 'NAN'으로 바꿈

    test = pd.read_csv(path + "test.csv")
    test = test.drop(["index"], axis=1)
    test.fillna("NAN", inplace=True)

    # absolute
    train["DAYS_EMPLOYED"] = train["DAYS_EMPLOYED"].map(lambda x: 0 if x > 0 else x)#0 보다 크면 0 아니면 그대로
    train["DAYS_EMPLOYED"] = np.abs(train["DAYS_EMPLOYED"]) #절댓값
    test["DAYS_EMPLOYED"] = test["DAYS_EMPLOYED"].map(lambda x: 0 if x > 0 else x)
    test["DAYS_EMPLOYED"] = np.abs(test["DAYS_EMPLOYED"])
    train["DAYS_BIRTH"] = np.abs(train["DAYS_BIRTH"])
    test["DAYS_BIRTH"] = np.abs(test["DAYS_BIRTH"])
    train["begin_month"] = np.abs(train["begin_month"]).astype(int)
    test["begin_month"] = np.abs(test["begin_month"]).astype(int)

    # DAYS_BIRTH 월별 / 주별 로 분리
    train["DAYS_BIRTH_month"] = np.floor(train["DAYS_BIRTH"] / 30) - (
        (np.floor(train["DAYS_BIRTH"] / 30) / 12).astype(int) * 12
    )
    train["DAYS_BIRTH_month"] = train["DAYS_BIRTH_month"].astype(int)
    train["DAYS_BIRTH_week"] = np.floor(train["DAYS_BIRTH"] / 7) - (
        (np.floor(train["DAYS_BIRTH"] / 7) / 4).astype(int) * 4
    )
    train["DAYS_BIRTH_week"] = train["DAYS_BIRTH_week"].astype(int)
    test["DAYS_BIRTH_month"] = np.floor(test["DAYS_BIRTH"] / 30) - (
        (np.floor(test["DAYS_BIRTH"] / 30) / 12).astype(int) * 12
    )
    test["DAYS_BIRTH_month"] = test["DAYS_BIRTH_month"].astype(int)
    test["DAYS_BIRTH_week"] = np.floor(test["DAYS_BIRTH"] / 7) - (
        (np.floor(test["DAYS_BIRTH"] / 7) / 4).astype(int) * 4
    )
    test["DAYS_BIRTH_week"] = test["DAYS_BIRTH_week"].astype(int)

    # Age
    train["Age"] = np.abs(train["DAYS_BIRTH"]) // 360
    test["Age"] = np.abs(test["DAYS_BIRTH"]) // 360

    # DAYS_EMPLOYED 월별 / 주별 로 분리
    train["DAYS_EMPLOYED_month"] = np.floor(train["DAYS_EMPLOYED"] / 30) - (
        (np.floor(train["DAYS_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    train["DAYS_EMPLOYED_month"] = train["DAYS_EMPLOYED_month"].astype(int)
    train["DAYS_EMPLOYED_week"] = np.floor(train["DAYS_EMPLOYED"] / 7) - (
        (np.floor(train["DAYS_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    train["DAYS_EMPLOYED_week"] = train["DAYS_EMPLOYED_week"].astype(int)
    test["DAYS_EMPLOYED_month"] = np.floor(test["DAYS_EMPLOYED"] / 30) - (
        (np.floor(test["DAYS_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    test["DAYS_EMPLOYED_month"] = test["DAYS_EMPLOYED_month"].astype(int)
    test["DAYS_EMPLOYED_week"] = np.floor(test["DAYS_EMPLOYED"] / 7) - (
        (np.floor(test["DAYS_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    test["DAYS_EMPLOYED_week"] = test["DAYS_EMPLOYED_week"].astype(int)

    # EMPLOYED 
    train["EMPLOYED"] = train["DAYS_EMPLOYED"] / 360 #np.floor를 할 필요가 있음
    test["EMPLOYED"] = test["DAYS_EMPLOYED"] / 360

    # before_EMPLOYED 생성
    train["before_EMPLOYED"] = train["DAYS_BIRTH"] - train["DAYS_EMPLOYED"]
    train["before_EMPLOYED_month"] = np.floor(train["before_EMPLOYED"] / 30) - (
        (np.floor(train["before_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    train["before_EMPLOYED_month"] = train["before_EMPLOYED_month"].astype(int)
    train["before_EMPLOYED_week"] = np.floor(train["before_EMPLOYED"] / 7) - (
        (np.floor(train["before_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    train["before_EMPLOYED_week"] = train["before_EMPLOYED_week"].astype(int)
    test["before_EMPLOYED"] = test["DAYS_BIRTH"] - test["DAYS_EMPLOYED"]
    test["before_EMPLOYED_month"] = np.floor(test["before_EMPLOYED"] / 30) - (
        (np.floor(test["before_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    test["before_EMPLOYED_month"] = test["before_EMPLOYED_month"].astype(int)
    test["before_EMPLOYED_week"] = np.floor(test["before_EMPLOYED"] / 7) - (
        (np.floor(test["before_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    test["before_EMPLOYED_week"] = test["before_EMPLOYED_week"].astype(int)

    # gender, car, reality 합쳐서 사용
    train["user_code"] = (
        train["gender"].astype(str)
        + "_"
        + train["car"].astype(str)
        + "_"
        + train["reality"].astype(str)
    )
    test["user_code"] = (
        test["gender"].astype(str)
        + "_"
        + test["car"].astype(str)
        + "_"
        + test["reality"].astype(str)
    )

    del_cols = [  #버릴 열
        "gender",
        "car",
        "reality",
        "email",
        "child_num",
        "DAYS_BIRTH",
        "DAYS_EMPLOYED",
        "family_size",
        "FLAG_MOBIL",
        "work_phone",
        "phone"
    ]
    train.drop(train.loc[train["family_size"] > 7, "family_size"].index, inplace=True)
    train.drop(del_cols, axis=1, inplace=True)
    test.drop(del_cols, axis=1, inplace=True)

    cat_cols = [ #
        "income_type",
        "edu_type",
        "family_type",
        "house_type",
        "occyp_type",
        "user_code",
    ]

    for col in cat_cols:
        label_encoder = LabelEncoder()
        label_encoder = label_encoder.fit(train[col])
        train[col] = label_encoder.transform(train[col])
        test[col] = label_encoder.transform(test[col])

    return train, test

# catboost 데이터 전처리
def cat_load_dataset() -> Tuple[pd.DataFrame, pd.DataFrame]:
    path = "/content/drive/MyDrive/data/"
    train = pd.read_csv(path + "train.csv")
    train = train.drop(["index"], axis=1)
    train.fillna("NAN", inplace=True)

    test = pd.read_csv(path + "test.csv")
    test = test.drop(["index"], axis=1)
    test.fillna("NAN", inplace=True)

    # absolute
    train["DAYS_EMPLOYED"] = train["DAYS_EMPLOYED"].map(lambda x: 0 if x > 0 else x)
    train["DAYS_EMPLOYED"] = np.abs(train["DAYS_EMPLOYED"])
    test["DAYS_EMPLOYED"] = test["DAYS_EMPLOYED"].map(lambda x: 0 if x > 0 else x)
    test["DAYS_EMPLOYED"] = np.abs(test["DAYS_EMPLOYED"])
    train["DAYS_BIRTH"] = np.abs(train["DAYS_BIRTH"])
    test["DAYS_BIRTH"] = np.abs(test["DAYS_BIRTH"])
    train["begin_month"] = np.abs(train["begin_month"]).astype(int)
    test["begin_month"] = np.abs(test["begin_month"]).astype(int)

    # income_total
    train = category_income(train)
    test = category_income(test)

    # DAYS_BIRTH
    train["DAYS_BIRTH_month"] = np.floor(train["DAYS_BIRTH"] / 30) - (
        (np.floor(train["DAYS_BIRTH"] / 30) / 12).astype(int) * 12
    )
    train["DAYS_BIRTH_month"] = train["DAYS_BIRTH_month"].astype(int)
    train["DAYS_BIRTH_week"] = np.floor(train["DAYS_BIRTH"] / 7) - (
        (np.floor(train["DAYS_BIRTH"] / 7) / 4).astype(int) * 4
    )
    train["DAYS_BIRTH_week"] = train["DAYS_BIRTH_week"].astype(int)
    test["DAYS_BIRTH_month"] = np.floor(test["DAYS_BIRTH"] / 30) - (
        (np.floor(test["DAYS_BIRTH"] / 30) / 12).astype(int) * 12
    )
    test["DAYS_BIRTH_month"] = test["DAYS_BIRTH_month"].astype(int)
    test["DAYS_BIRTH_week"] = np.floor(test["DAYS_BIRTH"] / 7) - (
        (np.floor(test["DAYS_BIRTH"] / 7) / 4).astype(int) * 4
    )
    test["DAYS_BIRTH_week"] = test["DAYS_BIRTH_week"].astype(int)

    # Age
    train["Age"] = np.abs(train["DAYS_BIRTH"]) // 360
    test["Age"] = np.abs(test["DAYS_BIRTH"]) // 360

    # DAYS_EMPLOYED
    train["DAYS_EMPLOYED_month"] = np.floor(train["DAYS_EMPLOYED"] / 30) - (
        (np.floor(train["DAYS_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    train["DAYS_EMPLOYED_month"] = train["DAYS_EMPLOYED_month"].astype(int)
    train["DAYS_EMPLOYED_week"] = np.floor(train["DAYS_EMPLOYED"] / 7) - (
        (np.floor(train["DAYS_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    train["DAYS_EMPLOYED_week"] = train["DAYS_EMPLOYED_week"].astype(int)
    test["DAYS_EMPLOYED_month"] = np.floor(test["DAYS_EMPLOYED"] / 30) - (
        (np.floor(test["DAYS_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    test["DAYS_EMPLOYED_month"] = test["DAYS_EMPLOYED_month"].astype(int)
    test["DAYS_EMPLOYED_week"] = np.floor(test["DAYS_EMPLOYED"] / 7) - (
        (np.floor(test["DAYS_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    test["DAYS_EMPLOYED_week"] = test["DAYS_EMPLOYED_week"].astype(int)

    # EMPLOYED
    train["EMPLOYED"] = np.floor(train["DAYS_EMPLOYED"] / 360).astype(int)
    test["EMPLOYED"] = np.floor(test["DAYS_EMPLOYED"] / 360).astype(int)

    # before_EMPLOYED
    train["before_EMPLOYED"] = train["DAYS_BIRTH"] - train["DAYS_EMPLOYED"]
    train["before_EMPLOYED_month"] = np.floor(train["before_EMPLOYED"] / 30) - (
        (np.floor(train["before_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    train["before_EMPLOYED_month"] = train["before_EMPLOYED_month"].astype(int)
    train["before_EMPLOYED_week"] = np.floor(train["before_EMPLOYED"] / 7) - (
        (np.floor(train["before_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    train["before_EMPLOYED_week"] = train["before_EMPLOYED_week"].astype(int)
    test["before_EMPLOYED"] = test["DAYS_BIRTH"] - test["DAYS_EMPLOYED"]
    test["before_EMPLOYED_month"] = np.floor(test["before_EMPLOYED"] / 30) - (
        (np.floor(test["before_EMPLOYED"] / 30) / 12).astype(int) * 12
    )
    test["before_EMPLOYED_month"] = test["before_EMPLOYED_month"].astype(int)
    test["before_EMPLOYED_week"] = np.floor(test["before_EMPLOYED"] / 7) - (
        (np.floor(test["before_EMPLOYED"] / 7) / 4).astype(int) * 4
    )
    test["before_EMPLOYED_week"] = test["before_EMPLOYED_week"].astype(int)

    # gender_car_reality
    train["user_code"] = (
        train["gender"].astype(str)
        + "_"
        + train["car"].astype(str)
        + "_"
        + train["reality"].astype(str)
    )
    test["user_code"] = (
        test["gender"].astype(str)
        + "_"
        + test["car"].astype(str)
        + "_"
        + test["reality"].astype(str)
    )
    # 삭제할 열
    del_cols = [
        "gender",
        "car",
        "reality",
        "email",
        "child_num",
        "DAYS_BIRTH",
        "DAYS_EMPLOYED",
        "family_size",
        "FLAG_MOBIL",
        "work_phone",
        "phone"
    ]
    
    train.drop(train.loc[train["family_size"] > 7, "family_size"].index, inplace=True)
    train.drop(del_cols, axis=1, inplace=True)#열 삭제
    test.drop(del_cols, axis=1, inplace=True)

    cat_cols = [
        "income_type",
        "edu_type",
        "family_type",
        "house_type",
        "occyp_type",
        "user_code",
    ]
    #
    for col in cat_cols: #알파벳 순서로 인코딩
        label_encoder = LabelEncoder()
        label_encoder = label_encoder.fit(train[col])
        train[col] = label_encoder.transform(train[col])
        test[col] = label_encoder.transform(test[col])

    return train, test
```


```python
# Catboost 계층적 k -fold
def stratified_kfold_cat(
    params: Dict[str, Union[int, float, str, List[str]]],
    n_fold: int,
    X: pd.DataFrame,
    y: pd.DataFrame,
    X_test: pd.DataFrame,
) -> Tuple[np.ndarray, np.ndarray]:
    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42) # random_state 는 데이터를 분할해줄때 패턴을 부여하는 값으로, 다음번에 42을 부여하면 똑같은 데이터셋으로 분할됨
    splits = folds.split(X, y) # 
    cat_oof = np.zeros((X.shape[0], 3)) # 모든 값이 0인 (26457,3)의 array 생성
    cat_preds = np.zeros((X_test.shape[0], 3))
    cat_cols = [c for c in X.columns if X[c].dtypes == "int64"]

    for fold, (train_idx, valid_idx) in enumerate(splits):# n_fold (0~n), (train 인덱스 번호, valid 인덱스 번호) train과 valid를 1:n-1로 나눔
        print(f"============ Fold {fold} ============\n")
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]
        train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols) # 병렬처리를 위한 클래스, 데이터가 numerical data일 떄 유용하다고 한다...
        valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)

        model = CatBoostClassifier(**params)

        model.fit(
            train_data,
            eval_set=valid_data,
            early_stopping_rounds=100, #100번 이상
            use_best_model=True,
            verbose=100,
        )

        cat_oof[valid_idx] = model.predict_proba(X_valid) # valid_idx 마다 preds 계산
        cat_preds += model.predict_proba(X_test) / n_fold # fold 마다 계산하고 n으로 나눔

    log_score = log_loss(y, cat_oof)
    print(f"Log Loss Score: {log_score:.5f}\n")
    return cat_oof, cat_preds


# Light GBM
def stratified_kfold_lgbm(
    params: Dict[str, Union[int, float, str]],
    n_fold: int,
    X: pd.DataFrame,
    y: pd.DataFrame,
    X_test: pd.DataFrame,
) -> Tuple[np.ndarray, np.ndarray]:
    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)
    splits = folds.split(X, y)
    lgb_oof = np.zeros((X.shape[0], 3)) #X.shape[0] = 25
    lgb_preds = np.zeros((X_test.shape[0], 3))

    for fold, (train_idx, valid_idx) in enumerate(splits):
        print(f"============ Fold {fold} ============\n")
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]
        pre_model = LGBMClassifier(**params)

        pre_model.fit(
            X_train,
            y_train,
            eval_set=[(X_train, y_train), (X_valid, y_valid)],
            early_stopping_rounds=100,
            verbose=100,
        )
        params2 = params.copy()
        params2["learning_rate"] = params["learning_rate"] * 0.1

        model = LGBMClassifier(**params2)
        model.fit(
            X_train,
            y_train,
            eval_set=[(X_train, y_train), (X_valid, y_valid)],
            early_stopping_rounds=100,
            verbose=100,
            #init_model=pre_model,
        )
        lgb_oof[valid_idx] = model.predict_proba(X_valid)
        lgb_preds += model.predict_proba(X_test) / n_fold

    log_score = log_loss(y, lgb_oof)
    print(f"Log Loss Score: {log_score:.5f}")

    return lgb_oof, lgb_preds


# XGBM
def stratified_kfold_xgb(
    params: Dict[str, Union[int, float, str]],
    n_fold: int,
    X: pd.DataFrame,
    y: pd.DataFrame,
    X_test: pd.DataFrame,
) -> Tuple[np.ndarray, np.ndarray]:

    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)
    splits = folds.split(X, y)
    xgb_oof = np.zeros((X.shape[0], 3))
    xgb_preds = np.zeros((X_test.shape[0], 3))

    for fold, (train_idx, valid_idx) in enumerate(splits):
        print(f"============ Fold {fold} ============\n")
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]

        model = XGBClassifier(**params)
        model.fit(
            X_train,
            y_train,
            eval_set=[(X_train, y_train), (X_valid, y_valid)],
            early_stopping_rounds=100,
            verbose=100,
        )

        xgb_oof[valid_idx] = model.predict_proba(X_valid)
        xgb_preds += model.predict_proba(X_test) / n_fold

    log_score = log_loss(y, xgb_oof)
    print(f"Log Loss Score: {log_score:.5f}")

    return xgb_oof, xgb_preds


# Random Foreset
def stratified_kfold_rf(
    params: Dict[str, Union[int, float, str, bool]],
    n_fold: int,
    X: pd.DataFrame,
    y: pd.DataFrame,
    X_test: pd.DataFrame,
) -> Tuple[np.ndarray, np.ndarray]:

    folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)
    splits = folds.split(X, y)
    rf_oof = np.zeros((X.shape[0], 3))
    rf_preds = np.zeros((X_test.shape[0], 3))

    for fold, (train_idx, valid_idx) in enumerate(splits):
        print(f"============ Fold {fold} ============\n")
        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]
        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]
        model = RandomForestClassifier(**params)
        model.fit(
            X_train,
            y_train,
        )

        rf_oof[valid_idx] = model.predict_proba(X_valid)
        rf_preds += model.predict_proba(X_test) / n_fold
        print(f"Log Loss Score: {log_loss(y_valid, rf_oof[valid_idx]):.5f}")

    log_score = log_loss(y, rf_oof)
    print(f"Log Loss Score: {log_score:.5f}")

    return rf_oof, rf_preds
```


```python
train_cat, test_cat = cat_load_dataset()

X = train_cat.drop("credit", axis=1)
y = train_cat["credit"]

X_test = test_cat.copy()

```


```python
cat_params = {
    "learning_rate": 0.026612467217016746,
    "l2_leaf_reg": 0.3753065117824262,
    "max_depth": 8,
    "bagging_temperature": 1,
    "min_data_in_leaf": 57,
    "max_bin": 494,
    "random_state": 42,
    "eval_metric": "MultiClass",
    "loss_function": "MultiClass",
    "od_type": "Iter",
    "od_wait": 500,
    "iterations": 10000,
    "cat_features": [
        "income_total",
        "income_type",
        "edu_type",
        "family_type",
        "house_type",
        #"FLAG_MOBIL",
        #"work_phone",
        #"phone",
        "occyp_type",
        "begin_month",
        "DAYS_BIRTH_month",
        "DAYS_BIRTH_week",
        "Age",
        "EMPLOYED",
        "DAYS_EMPLOYED_month",
        "DAYS_EMPLOYED_week",
        "before_EMPLOYED",
        "before_EMPLOYED_month",
        "before_EMPLOYED_week",
        "user_code",
    ],
}

cat_oof, cat_preds = stratified_kfold_cat(cat_params, 2, X, y, X_test)
```


```python
train, test = load_dataset()
X = train.drop("credit", axis=1)
y = train["credit"]
X_test = test.copy()
X.shape
```


```python
lgb_params = {
    "reg_alpha": 5.998770177220496e-05,
    "reg_lambda": 0.07127674208132959,
    "max_depth": 18,
    "num_leaves": 125,
    "colsample_bytree": 0.4241631237880101,
    "subsample": 0.8876057928391585,
    "subsample_freq": 5,
    "min_child_samples": 5,
    "max_bin": 449,
    "random_state": 42,
    "boosting_type": "gbdt",
    "learning_rate": 0.05,
    "n_estimators": 10000,
    "objective": "multiclass",
    "metric": "multi_logloss",
}
lgbm_oof, lgbm_preds = stratified_kfold_lgbm(lgb_params, 2, X, y, X_test)
```


```python
xgb_params = {
    "eta": 0.023839252347297356,
    "reg_alpha": 6.99554614267605e-06,
    "reg_lambda": 0.010419988953061583,
    "max_depth": 15,
    "max_leaves": 159,
    "colsample_bytree": 0.4515469593932409,
    "subsample": 0.7732694309118915,
    "min_child_weight": 5,
    "gamma": 0.6847131315687576,
    "random_state": 42,
    "n_estimators": 10000,
    "objective": "multi:softmax",
    "eval_metric": "mlogloss",
}
xgb_oof, xgb_preds = stratified_kfold_xgb(xgb_params, 2, X, y, X_test)
```


```python
rf_params = {
        "criterion": "gini",
        "n_estimators": 300,
        "min_samples_split": 10,
        "min_samples_leaf": 2,
        "max_features": "auto",
        "oob_score": True,
        "random_state": 42,
        "n_jobs": -1,
    }
rf_oof, rf_preds = stratified_kfold_rf(rf_params, 2, X, y, X_test)
```


```python
train, test = load_dataset()
train_x = train.drop("credit", axis = 1)
train_y = train['credit'].values
```


```python
train_pred = np.concatenate([cat_oof, lgbm_oof, xgb_oof, rf_oof], axis=1) #값 합치기
train_pred.shape
```


```python
test_pred = np.concatenate([cat_preds, lgbm_preds, xgb_preds, rf_preds], axis=1) #값 합치기
test_pred.shape
```


```python
device = "cuda" if torch.cuda.is_available() else "cpu"
```


```python
n_fold = 2
folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)
splits = folds.split(train_pred, train_y)
net_oof = np.zeros((train_pred.shape[0], 3))
net_preds = np.zeros((test_pred.shape[0], 3))
for fold, (train_idx, valid_idx) in enumerate(splits):
    print(f"============ Fold {fold} ============\n")
    X_train, X_valid = train_pred[train_idx], train_pred[valid_idx]
    y_train, y_valid = train_y[train_idx], train_y[valid_idx]
    model = TabNetMultiTaskClassifier(
            n_d=64, n_a=64, n_steps=1,
            lambda_sparse=1e-4,
            optimizer_fn=torch.optim.Adam,
            optimizer_params=dict(lr=2e-2),
            scheduler_params = {"gamma": 0.9, "step_size": 50},
            scheduler_fn=torch.optim.lr_scheduler.StepLR,
            mask_type="entmax", 
            device_name=device
    )

    model.fit(
        X_train, y_train.reshape(-1,1),
        eval_set=[(X_valid, y_valid.reshape(-1,1))],
        max_epochs=100,
        batch_size=1024,
        eval_metric=["logloss"],
        virtual_batch_size=128,
        num_workers=1,
        drop_last=False
    )
    net_oof[valid_idx] = model.predict_proba(X_valid)
    net_preds += model.predict_proba(test_pred)[0] / n_fold
log_score = log_loss(train_y, net_oof)
print(f"Log Loss Score: {log_score:.5f}")
```


```python
submission = pd.read_csv("/content/drive/MyDrive/abc.csv")
submission.iloc[:, 1:] = net_preds
submission.to_csv("meta_ensemble_submit.csv", index=False)
```


```python
import numpy as np
a = np.zeros((10, 1))
b = np.zeros((10, 1))
c = np.concatenate([a, b], axis=1)
d = b = np.zeros((10, 1))

f = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)
s = f.split(c, d)
```


```python

```
